<picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://user-images.githubusercontent.com/81682248/226963550-21eaaf59-ee3c-49a9-8e75-b76d740ddd09.png">
  <img width="300" alt="Graphcore logo" src="https://user-images.githubusercontent.com/81682248/226963440-9cae0ac4-ebf5-407a-9870-5679e434cada.png">
</picture>

# GPT-J and GPT-J-6B on IPUs

![GPT-J header](gpt-j-header.jpg)

GPT-J is an open-source alternative from EleutherAI to OpenAI's GPT-3. Available for anyone to download, GPT-J can be successfully fine-tuned to perform just as well as large models on a range of NLP tasks including question answering, sentiment analysis, and named entity recognition.

Try running GPT-J for yourself on Paperspace with Graphcore's IPU (Intelligence Processing Unit), a completely new kind of massively parallel processor to accelerate machine intelligence. Access advanced, cost-efficient IPU compute on demand in the cloud on Paperspace to build, fine-tune and deploy AI models such as GPT-J.



## GPT-J notebooks powered by IPUs

| Notebook | Framework | Type | Try for Free
| ------------- | ------------- | ------------- | ------------- |
| Textual Entailment on IPU using GPT-J - Fine-tuning | Hugging Face | Fine-tuning | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://ipu.dev/czHSUi)
| Text generation with GPT-J 6B | Hugging Face | Inference | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://ipu.dev/OMBQrl)

In the **Textual Entailment on IPU using GPT-J - Fine-tuning** notebook, we show how to fine-tune a pre-trained GPT-J model running on a 16-IPU system on Paperspace. We will explain how you can fine-tune GPT-J for Text Entailment on the GLUE MNLI dataset to reach SOTA performance, whilst being much more cost-effective than its larger cousins.

In the **Text generation with GPT-J 6B** notebook, we demonstrate how easy it is to run GPT-J on the Graphcore IPU using this implementation of the model and ðŸ¤— Hub checkpoints of the model weights.


## GPT-J resources

* [GitHub Code](https://github.com/graphcore/Gradient-HuggingFace/tree/main/gptj-text-generation)
* [Hugging Face Model](https://huggingface.co/EleutherAI/gpt-j-6b)
* [Blog](https://www.graphcore.ai/posts/fine-tuned-gpt-j-a-cost-effective-alternative-to-gpt-4-for-nlp-tasks)
* [How-to walkthrough blog](https://www.graphcore.ai/posts/gpt-j-fine-tuning-tutorial-walkthrough)
* [Original Paper](https://arxiv.org/abs/2212.04356)

To take your GPT-J usage on IPUs further, or speak to an expert, please feel free to [contact us](https://www.graphcore.ai/contact).

## IPU community

Join our growing community and interact with AI experts, IPU developers and researchers. Hear the latest IPU news and get access to our newest models.

[![Join our Slack Community](https://img.shields.io/badge/Slack-Join%20Graphcore's%20Community-blue?style=flat-square&logo=slack)](https://www.graphcore.ai/join-community)
