<picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://user-images.githubusercontent.com/81682248/226963550-21eaaf59-ee3c-49a9-8e75-b76d740ddd09.png">
  <img width="300" alt="Graphcore logo" src="https://user-images.githubusercontent.com/81682248/226963440-9cae0ac4-ebf5-407a-9870-5679e434cada.png">
</picture>

# GPT-J

<p align="center"><img width="500" alt="Waveform" src="gpt-j-header.jpg"></p>

GPT-J is a versatile speech recognition model that can transcribe speech as well as perform multi-lingual translation and recognition tasks. It was trained on diverse datasets to give human-level speech recognition performance without the need for fine-tuning.

Graphcore's IPU (Intelligence Processing Unit) is a completely new kind of massively parallel processor to accelerate machine intelligence. Developers can access advanced, cost-efficient IPU compute on-demand in the cloud for building, fine-tuning and deploying AI models such as Whisper.


## GPT-J notebooks powered by IPUs

| Notebook | Framework | Type | Try for Free
| ------------- | ------------- | ------------- | ------------- |
| Textual Entailment on IPU using GPT-J - Fine-tuning | Hugging Face | Fine-tuning | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)]()

[Description of notebook, for example]
In this notebook, we demonstrate fine-tuning GPT-J 6B on the using Whisper Tiny for speech recognition and transcription on the IPU. We use Optimum Graphcore - a new open-source library and toolkit that enables developers to access IPU-optimized models certified by Hugging Face. Only a few lines of code are needed to get this state-of-the-art automated speech recognition model running on IPUs.

| Notebook | Framework | Type | Try for Free
| ------------- | ------------- | ------------- | ------------- |
| Text generation with GPT-J 6B | Hugging Face | Inference | [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)]()

[Description of notebook, for example]
In this Paperspace Gradient notebook, we demonstrate using Whisper Tiny for speech recognition and transcription on the IPU. We use Optimum Graphcore - a new open-source library and toolkit that enables developers to access IPU-optimized models certified by Hugging Face. Only a few lines of code are needed to get this state-of-the-art automated speech recognition model running on IPUs.



## GPT-J resources

* [GitHub Code](https://github.com/graphcore/Gradient-HuggingFace/tree/main/early-access/whisper)
* [Hugging Face Model](https://huggingface.co/EleutherAI/gpt-j-6b)
* [Blog](https://www.graphcore.ai/posts/fine-tuned-gpt-j-a-cost-effective-alternative-to-gpt-4-for-nlp-tasks)
* [How-to walkthrough blog](https://www.graphcore.ai/posts/gpt-j-fine-tuning-tutorial-walkthrough)
* [Original Paper](https://arxiv.org/abs/2212.04356)

To take your Whisper usage on IPUs further, or speak to an expert, please feel free to [contact us](https://www.graphcore.ai/speak-to-an-expert-whisper-ai).

## IPU community

Join our growing community and interact with AI experts, IPU developers and researchers. Hear the latest IPU news and get access to our newest models.

[![Join our Slack Community](https://img.shields.io/badge/Slack-Join%20Graphcore's%20Community-blue?style=flat-square&logo=slack)](https://www.graphcore.ai/join-community)
